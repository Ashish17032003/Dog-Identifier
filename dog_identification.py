# -*- coding: utf-8 -*-
"""Dog-Identification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s-dEKDZAbRDWG72aXh9LcnQqa3mznALg
"""

# Run this cell to connect to google drive

from google.colab import drive
drive.mount('/content/drive')

"""#**ðŸ¶ End-to-end Multi-class Dog Breed Classification.**


This notebook builds an end-to-end multi-class image classifier using TensorFlow 2.x and TensorFlow Hub.

##1. Problem

Identifying the breed of a dog given an image of a dog.

When I'm sitting at the cafe and I take a photo of a dog, I want to know what breed of dog it is.


##2. Data

The data we're using is from Kaggle's dog breed identification competition.

https://www.kaggle.com/c/dog-breed-identification/data


##3. Evaluation

The evaluation is a file with prediction probabilities for each dog breed of each test image.

https://www.kaggle.com/c/dog-breed-identification/overview/evaluation


##4. Features

Some information about the data:

    We're dealing with images (unstructured data) so it's probably best we use deep learning/transfer learning.
    There are 120 breeds of dogs (this means there are 120 different classes).
    There are around 10,000+ images in the training set (these images have labels).
    There are around 10,000+ images in the test set (these images have no labels, because we'll want to predict them).


"""

# Unzip the uploaded data into Google Drive (one time operation)
# !unzip "drive/My Drive/Dog Vision/dog-breed-identification.zip" -d "drive/My Drive/Dog Vision/"

"""# Get our workspace ready
* Import TensorFlow 2.x âœ…
* Import TensorFlow Hub âœ…
* Make sure we're using a GPU âœ…

"""

# Import necessary tools

import tensorflow as tf
import tensorflow_hub as hub 
print("TF version:", tf.__version__)
print("TF Hub version:", hub.__version__)

# Check for GPU availability
print("GPU", "Available (YESSSS!!!!!)" if tf.config.list_physical_devices("GPU") else "not available :(")

"""GPU is a computer chip which is faster at doing numerical computing. And since machine learning is all about finding patterns in numbers, that's what we're after.

Running this for the first time in Colab will let us know there's no GPU available.

This is because by default Colab runs on a computer located on Google's servers which doesn't have a GPU attached to it.

But we can fix this going to runtime and then changing the runtime type:

Go to Runtime.

1.   Click "Change runtime type".
2.   Where it says "Hardware accelerator", choose "GPU" (don't worry about TPU for now but feel free to research them).
3.   Click save.
4.   The runtime will be restarted to activate the new hardware, so you'll have to rerun the above cells.
5.   If the steps have worked you should see a print out saying "GPU available".

If you want an example of how much a GPU speeds up computing, [Google Colab have a demonstration notebook available.](https://https://colab.research.google.com/notebooks/gpu.ipynb)

#Getting our data ready (turning into Tensors)

With all machine learning models, our data has to be in numerical format. So that's what we'll be doing first. Turning our images into Tensors (numerical representations).

Let's start by accessing our data and checking out the labels.
"""

# Checkout the labels of our data

import pandas as pd
labels_csv = pd.read_csv("drive/My Drive/Dog Vision/Extracted/extract/labels.csv")
print(labels_csv.describe())
print(labels_csv.head())

labels_csv.head()

# How many images are there of each breed?
labels_csv["breed"].value_counts().plot.bar(figsize=(20, 10))

# labels_csv["breed"].value_counts().mean() # What's the median number of images per class?

labels_csv["breed"].value_counts().median()

# Let's view an image

from IPython.display import Image
Image("drive/My Drive/Dog Vision/Extracted/extract/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg")

"""## Getting images and their labels

Let's get a list of all of our image file pathnames.
"""

labels_csv.head()

# Create pathnames from Image ID's

filenames = ["drive/My Drive/Dog Vision/Extracted/extract/train/" + fname + ".jpg" for fname in labels_csv["id"]]

# Check the first 10
filenames[:10]

import os
if len(os.listdir("drive/My Drive/Dog Vision/Extracted/extract/train/")) == len(filenames):
  print("Filenames match actual amount of files!!! Proceed.")
else:
  print("Filenames do no match actual amount of files, check the target directory.")

"""
If amount of files don't match 
you can use this "list(set(name of files from the drive)-set(name from the labels files))" and this will gives you the file name of those not mathes and you can just go back to deleted from you drive. 


import os

define the label dataset  
1. label_dataset = ["dog1.jpg", "dog2.jpg", "cat1.jpg", "cat2.jpg"]

define the directory of the image folder
2. img_folder = "path/to/dog/folder"

get the list of images in the folder
3. img_list = os.listdir(img_folder)

find the difference between the two lists
4. diff = set(label_dataset) - set(img_list)

print the difference
5. print(diff)"""

# list(set(os.listdir("drive/My Drive/Dog Vision/train/")) - set(os.list("drive/My Drive/Dog Vision/labels.csv")))
# len(filenames) - len(os.listdir("drive/My Drive/Dog Vision/train/"))
# The same problem arises with me, delete the data and re-upload it and make sure to have a stable internet connection during the downloading period.

# One more check
Image(filenames[9000])

labels_csv["breed"][9000]

"""Since we've now got our training image filepaths in a list, let's prepare our labels.

"""

import numpy as np

labels = labels_csv["breed"]
labels = np.array(labels)
# labels = labels_csv["breed"].to_numpy()  does the same thing as above 2 lines combined
labels

len(labels)

# See if number of labels matches the number of filenames
if len(labels) == len(filenames):
  print("Number of labels matches number of filenames!")
else:
  print("Number of labels does not match number of filenames, check data directories!")

"""If it all worked, we should have the same amount of images and labels.

Finally, since a machine learning model can't take strings as input (what labels currently is), we'll have to convert our labels to numbers.

To begin with, we'll find all of the unique dog breed names.

Then we'll go through the list of labels and compare them to unique breeds and create a list of booleans indicating which one is the real label (True) and which ones aren't (False).
"""

# Find the unique label values
unique_breeds = np.unique(labels)
len(unique_breeds)

unique_breeds

"""The length of unique_breeds should be 120, meaning we're working with images of 120 different breeds of dogs.

Now use unique_breeds to help turn our labels array into an array of booleans.

"""

# Turn a single label into an array

print(labels[0])
labels[0] == unique_breeds  # use comparison operator to create boolean array

# Turn every label into a boolean array
boolean_labels = [label == unique_breeds for label in labels]
boolean_labels[:2]

len(boolean_labels)

"""Why do it like this?

Remember, an important concept in machine learning is converting your data to numbers before passing it to a machine learning model.

In this case, we've transformed a single dog breed name such as boston_bull into a one-hot array.

Let's see an example.

"""

# Example: Turning a boolean array into integers
print(labels[0]) # original label
print(np.where(unique_breeds == labels[0])) # index where label occurs
print(boolean_labels[0].argmax()) # index where label occurs in boolean array
print(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs in unique breeds

"""Wonderful! Now we've got our labels in a numeric format and our image filepaths easily accessible (they aren't numeric yet), let's split our data up."""

print(labels[2])
print(boolean_labels[2].astype(int))

boolean_labels[:2]

filenames[:10]

"""## Creating our own validation set

Since the dataset from Kaggle doesn't come with a validation set (a split of the data we can test our model on before making final predicitons on the test set), let's make one.

We could use Scikit-Learn's [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function or we could simply make manual splits of the data.

For accessibility later, let's save our filenames variable to X (data) and our labels to y.

*   https://www.fast.ai/posts/2017-11-13-validation-sets.html


"""

# Setup X & Y Variables

X = filenames
y = boolean_labels

len(filenames)

"""Since we're working with 10,000+ images, it's a good idea to work with a portion of them to make sure things are working before training on them all.

This is because computing with 10,000+ images could take a fairly long time. And our goal when working through machine learning projects is to reduce the time between experiments.

Let's start experimenting with 1000 and increase it as we need.

"""

# Set number of images to use for experimenting

NUM_IMAGES = 1000 #@param {type:"slider", min:1000, max:10000, step:1000}

# Let's split our data into train and validation sets
from sklearn.model_selection import train_test_split

# Split them into training and validation of total size NUM_IMAGES
X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],
                                                  y[:NUM_IMAGES],
                                                  test_size=0.2,
                                                  random_state=42)

len(X_train), len(y_train), len(X_val), len(y_val)

# Check out the training data (image file paths and labels)
X_train[:5], y_train[:2]

"""#Preprocessing images (turning images into Tensors)

Our labels are in numeric format but our images are still just file paths.

Since we're using TensorFlow, our data has to be in the form of Tensors.

A Tensor is a way to represent information in numbers. If you're familar with NumPy arrays (you should be), a Tensor can be thought of as a combination of NumPy arrays, except with the special ability to be used on a GPU.

Because of how TensorFlow stores information (in Tensors), it allows machine learning and deep learning models to be run on GPUs (generally faster at numerical computing).

To preprocess our images into Tensors we're going to write a function which does a few things: (almost same workflow for anything else)

1. Takes an image filename as input.
2. Uses TensorFlow to read the file and save it to a variable, image.
3. Turn our image (a jpeg file) into Tensors.
4. Normalize our image (convert color channel values from from 0-255 to 0-1).
5. Resize the image to be of shape (224, 224).
6. Return the modified image.

A good place to read about this type of function is the [TensorFlow documentation on loading images.](https://www.tensorflow.org/tutorials/load_data/images) 

You might be wondering why (224, 224), which is (heigh, width). It's because this is the size of input our model (we'll see this soon) takes, an image which is (224, 224, 3).

What? Where's the 3 from? We're getting ahead of ourselves but that's the number of colour channels per pixel, red, green and blue. (Convolution Neural Networks)

Let's make this a little more concrete.


Before we do, let's see what importing an image looks like.
"""

# Convert image to NumPy array

from matplotlib.pyplot import imread
image = imread(filenames[42])
image.shape

"""Notice the shape of image. It's (257, 350, 3). This is height, width, colour channel value.

And you can easily convert it to a Tensor using tf.constant().

"""

image.max() , image.min()

image[:2]

# turn image into a tensor
tf.constant(image)[:2]

"""Ok, now let's build that function we were talking about."""

# Define image size  https://stackoverflow.com/questions/43434418/is-there-any-particular-reason-why-people-pick-224x224-image-size-for-imagenet-e
IMG_SIZE = 224


# Create a function for preprocessing images

def process_image(image_path, img_size=IMG_SIZE):
  """
  Takes an image file path and turns it into a Tensor.
  """
  # Read in image file
  image = tf.io.read_file(image_path)

  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)
  image = tf.image.decode_jpeg(image, channels=3)

  # Convert the colour channel values from 0-225 values to 0-1 values (Normalization)
  image = tf.image.convert_image_dtype(image, tf.float32)

  # Resize the image to our desired size (224, 244)
  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])
  return image

# test code for above cell
# test = tf.io.read_file(filenames[20])
# tf.image.decode_jpeg(test, channels=3)

"""##Creating data batches

Wonderful. Now we've got a function to convert our images into Tensors, we'll now build one to turn our data into batches (more specifically, a TensorFlow BatchDataset).

What's a batch?

A batch (also called mini-batch) is a small portion of your data, say 32 (32 is generally the default batch size) images and their labels. In deep learning, instead of finding patterns in an entire dataset at the same time, you often find them one batch at a time.

Let's say you're dealing with 10,000+ images (which we are). Together, these files may take up more memory than your GPU has. Trying to compute on them all would result in an error.

Instead, it's more efficient to create smaller batches of your data and compute on one batch at a time.

TensorFlow is very efficient when your data is in batches of (image, label) Tensors. So we'll build a function to do create those first. We'll take advantage of of process_image function at the same time.


Why turn our data into batches?

Let's say you're trying to process 10,000+ images in one go... they all might not fit into memory.

So that's why we do about 32 (this is the batch size) images at a time (you can manually adjust the batch size if need be).

In order to use TensorFlow effectively, we need our data in the form of Tensor tuples which look like this: `(image, label)`.       
{image as form of tensor and labels as pairs, so then we pass 32 of these at a time to our machine learning model and then it would figure out the patterns in this image related to this label}
"""

# Create a simple function to return a tuple (image, label)
def get_image_label(image_path, label):
  """
  Takes an image file path name and the associated label,
  processes the image and returns a tuple of (image, label).
  """
  image = process_image(image_path)
  return image, label

# Demo of the above
( process_image(X[42]), tf.constant(y[42]) )

"""Now we've got a simple function to turn our image file path names and their associated labels into tuples (we can turn these into Tensors next), we'll create a function to make data batches.

Because we'll be dealing with 3 different sets of data (training, validation and test), we'll make sure the function can accomodate for each set.

We'll set a default batch size of 32 because according to [Yann Lecun](https://twitter.com/ylecun/status/989610208497360896?s=20) (one of the OG's of deep learning), friends don't let friends train with batch sizes over 32.

Now we've got a way to turn our data into tuples of Tensors in the form: `(image, label)`, let's make a function to turn all of our data `(X & y)` into batches!

"""

# Test code for below cell ( performed  to check the use of tensor_slices)

#data = tf.data.Dataset.from_tensor_slices(tf.constant(X))
#for element in data:
#print(data)

#dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])
#print(dataset)
#for element in dataset:
#print(element)

# Define the batch size, 32 is a good start
BATCH_SIZE = 32

# Create a function to turn data into batches
def create_data_batches(X, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):
  """
  Creates batches of data out of image (X) and label (y) pairs.
  Shuffles the data if it's training data but doesn't shuffle if it's validation data.
  Also accepts test data as input (no labels).
  """
  # if the data is a test dataset, we probably don't have labels
  if test_data:
    print("Creating test data batches....")
    data = tf.data.Dataset.from_tensor_slices(tf.constant(X))  # only filepaths (no labels) (creates a dataset whose elements are slices of the given dataset) https://www.tensorflow.org/api_docs/python/tf/data/Dataset
    data_batch = data.map(process_image).batch(batch_size) # https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map
    return data_batch

  # If the data if a valid dataset, we don't need to shuffle it
  elif valid_data:
    print("Creating validation data batches...")
    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths
                                               tf.constant(y))) # labels
    data_batch = data.map(get_image_label).batch(batch_size)
    # The .map function applies a certain function to the complete dataset, in our case (in data.map(get_image_label)), 
    # it's taking the image path and outputting the batch of inputs & labels.  The .map function automatically input the parameters and takes the output from the function
    return data_batch

  else:
    # If the data is a training dataset, we shuffle it
    print("Creating training data batches...")
    # Turn filepaths and labels into Tensors
    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), # filepaths
                                              tf.constant(y))) # labels
    
    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images
    data = data.shuffle(buffer_size=len(X))

    """
    We shuffle the training data in order to remove any potential order from with the data as it's imported. 
    For example, if you imported all of your data one dog breed at a time, a model might learn things assosciated with one dog breed stronger than another. So to ensure the best chance of our model being robust to dogs it sees in the real world (in random order), we train it on images in random order. The same goes for other types of training data.
    This answer on the data science Stack Exchange has a great explanation too: https://datascience.stackexchange.com/a/24524
    """

    # Create (image, label) tuples (this also turns the image path into a preprocessed image)
    data = data.map(get_image_label)

    # Turn the data into batches
    data_batch = data.batch(batch_size)
  return data_batch

# Create training and validation data batches
train_data = create_data_batches(X_train, y_train)
val_data = create_data_batches(X_val, y_val, valid_data=True)

# Check out the different attributes of our data batches
train_data.element_spec, val_data.element_spec

"""Look at that! We've got our data in batches, more specifically, they're in Tensor pairs of (images, labels) ready for use on a GPU.

But having our data in batches can be a bit of a hard concept to understand. Let's build a function which helps us visualize what's going on under the hood.

## Visualizing Data Batches

Our data is now in batches, however, these can be a little hard to understand/comprehend, let's visualize them!
"""

import matplotlib.pyplot as plt

# Create a function for viewing images in a data batch
def show_25_images(images, labels):
  """
  Displays a plot of 25 images and their labels from a data batch.
  https://matplotlib.org/stable/tutorials/introductory/pyplot.html
  """
  # Setup the figure
  plt.figure(figsize=(10, 10))
  # Loop through 25 (for displaying 25 images)
  for i in range(25):
    # Create subplots (5 rows, 5 columns)
    """
    The subplot() function takes three arguments that describes the layout of the figure.
    The layout is organized in rows and columns, which are represented by the first and second argument.
    The third argument represents the index of the current plot.
    """
    ax = plt.subplot(5, 5, i+1)  # https://www.w3schools.com/python/matplotlib_subplot.asp

    # Display an image 
    plt.imshow(images[i])
    # Add the image label as the title
    plt.title(unique_breeds[labels[i].argmax()])
    # Turn the grid lines off
    plt.axis("off")

train_data

"""To make computation efficient, a batch is a tighly wound collection of Tensors.

So to view data in a batch, we've got to unwind it.

We can do so by calling the as_numpy_iterator() method on a data batch.

This will turn our a data batch into something which can be iterated over.

Passing an iterable to next() will return the next item in the iterator.

In our case, next will return a batch of 32 images and label pairs.

Note: Running the cell below and loading images may take a little while.


https://www.tensorflow.org/api_docs/python/tf/data/Dataset#as_numpy_iterator



"""

# Test code for the below cell
# dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])
# for element in dataset:
# print(element)

# for element in dataset.as_numpy_iterator():
#  print(element)

# Visualize training images from the training data batch ( next returns the next item from the iterator)
train_images, train_labels = next(train_data.as_numpy_iterator())  # as_numpy_iterator() An iterable over the elements of the dataset, with their tensors converted to numpy arrays.
len(train_images), len(train_labels)
show_25_images(train_images, train_labels)

#  Now let's visualize our validation set
val_images, val_labels = next(val_data.as_numpy_iterator())
show_25_images(val_images, val_labels)

"""# Creating and training a model

Now our data is ready, let's prepare it modelling. We'll use an existing model from [TensorFlow Hub](https:/https://tfhub.dev//).

TensorFlow Hub is a resource where you can find pretrained machine learning models for the problem you're working on.

Using a pretrained machine learning model is often referred to as transfer learning.
Why use a pretrained model?

Building a machine learning model and training it on lots from scratch can be expensive and time consuming.

Transfer learning helps eliviate some of these by taking what another model has learned and using that information with your own problem.
How do we choose a model?

Since we know our problem is image classification (classifying different dog breeds), we can navigate the [TensorFlow Hub page by our problem domain (image)](https:https://tfhub.dev/s?module-type=image-augmentation,image-classification,image-feature-vector,image-generator,image-object-detection,image-others,image-style-transfer,image-rnn-agent//). 

We start by choosing the image problem domain, and then can filter it down by subdomains, in our case, image classification.

Doing this gives a list of different pretrained models we can apply to our task.

Clicking on one gives us information about the model as well as instructions for using it.

For example, clicking on the [mobilenet_v2_130_224](https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5) model, tells us this model takes an input of images in the shape 224, 224. It also says the model has been trained in the domain of image classification.

Let's try it out.


## Building a model

Before we build a model, there are a few things we need to define:
*   The input shape (our images shape, in the form of Tensors) to our model.
*   The output shape (image labels, in the form of Tensors) of our model.
*   The URL of the model we want to use from TensorFlow Hub - https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4

"""

IMG_SIZE

# Setup input shape to the model
INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels

# Setup output shape of our model
OUTPUT_SHAPE = len(unique_breeds)

# Setup model URL from TensorFlow Hub
MODEL_URL = "https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4"

INPUT_SHAPE

"""Now we've got the inputs, outputs and model we're using ready to go. We can start to put them together

There are many ways of building a model in TensorFlow but one of the best ways to get started is to use the [Keras API](https://www.tensorflow.org/guide/keras/sequential_model).

Defining a deep learning model in Keras can be as straightforward as saying, "here are the layers of the model, the input shape and the output shape, let's go!"

Knowing this, let's create a function which:

1. Takes the input shape, output shape and the model we've chosen's URL as parameters.
2. Defines the layers in a Keras model in a sequential fashion (do this first, then this, then that). { Sequential vs Functional API  ---->  https://youtu.be/EvGS3VAsG4Y }
3. Compiles the model (says how it should be evaluated and improved).
4. Builds the model (tells it what kind of input shape it'll be getting).
5. Returns the model.


All of these steps can be found here: https://www.tensorflow.org/guide/keras/overview

1. https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53
2. https://en.wikipedia.org/wiki/Softmax_function
3. https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c
"""

# https://www.tensorflow.org/guide/keras/sequential_model

# Create a function which builds a Keras model

def create_model(input_shape = INPUT_SHAPE, output_shape = OUTPUT_SHAPE, model_url = MODEL_URL) :
  print("Building model with : , model_url")

  # Setup model layers
  model = tf.keras.Sequential([ # stack of layers that takes input , find patterns and then gives an output
  hub.KerasLayer(model_url), # Layer 1 (input layer) which is actually the mobilenetv2 architecture contating series of convolutions which finds patterns in out input images and learn the features of those images (lines and all)
  tf.keras.layers.Dense(units=OUTPUT_SHAPE,
                        activation="softmax") # Layer 2 (output layer) .... softmax converts those patterns into numbers between 0 and 1 and the highest number is our label
  
  ])
  # Compile the model
  model.compile( 
      loss=tf.keras.losses.CategoricalCrossentropy(),  # https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/
      optimizer=tf.keras.optimizers.Adam(),
      metrics=["accuracy"]  # https://www.tensorflow.org/api_docs/python/tf/keras/metrics
  )

  # Build the model
  model.build(input_shape)

  return model

model = create_model()
model.summary()

"""## Creating callbacks

Callbacks are helper functions a model can use during training to do such things as save its progress, check its progress or stop training early if a model stops improving.

We'll create two callbacks, one for TensorBoard which helps track our models progress and another for early stopping which prevents our model from training for too long.

### TensorBoard Callback

To setup a TensorBoard callback, we need to do 3 things:
1. Load the TensorBoard notebook extension âœ…
2. Create a TensorBoard callback which is able to save logs to a directory and pass it to our model's `fit()` function. âœ…
3. Visualize our models training logs with the `%tensorboard` magic function (we'll do this after model training).

https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard
"""

# Commented out IPython magic to ensure Python compatibility.
# Load Tensorboard notebookk extension
# %load_ext tensorboard

import datetime 

# Create a function to build a TensorBoard Callback
def create_tensorboard_callback():
  # Create a log directory for storing TensorBoard logs 
  logdir = os.path.join("drive/My Drive/Dog Vision/logs",
                        # Make it so the logs get tracked whenever we run an experiment
                        datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
                        )
  return tf.keras.callbacks.TensorBoard(logdir)

"""Lets create an early stopping callback. Early stopping helps prevent overfitting. so our model learning the training data too well by stopping a model when a certain evaluation metric stops improving. 
https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping
"""

# Create early stopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(monitor="val_accuracy",
                                                  patience=3)

"""## Training a model (on subset of data)

Our first model is only going to train on 1000 images, to make sure everything is working.
"""

NUM_EPOCHS = 100 #@param {type:"slider", min:10, max:100, step:10}

# how many passes of data we would like our model to do

# Check to make sure we're still running on a GPU
print("GPU", "available (YESSS!!!!!!)" if tf.config.list_physical_devices("GPU") else "not available :(")

"""Let's create a function which trains a model.

* Create a model using `create_model()`
* Setup a TensorBoard callback using `create_tensorboard_callback()`
* Call the `fit()` function on our model passing it the training data, validation data, number of epochs to train for (`NUM_EPOCHS`) and the callbacks we'd like to use
* Return the model
"""

# Build a function to train and return a trained model

def train_model():
  """
  Trains a given model and returns the trained version.
  """
  # Create a model
  model = create_model()

  # Create new TensorBoard session everytime we train a model
  tensorboard = create_tensorboard_callback()

  # Fit the model to the data passing it the callbacks we created
  model.fit(x=train_data, # which is a data batch which contains the imahges and labels
            epochs=NUM_EPOCHS,
            validation_data=val_data, # also a data batch
            validation_freq=1, # how often we want to test the patterns that our model has found on our validation set
            callbacks=[tensorboard, early_stopping])
  
  # Return the fitted model
  return model

"""Note: When training a model for the first time, the first epoch will take a while to load compared to the rest. This is because the model is getting ready and the data is being initialised. Using more data will generally take longer, which is why we've started with ~1000 images. After the first epoch, subsequent epochs should take a few seconds.

"""

# Fit the model to the data
# model = train_model()

"""Question: It looks like our model is overfitting because it's performing far better on the training dataset than the validation dataset, what are some ways to prevent model overfitting in deep learning neural networks?

Note: Overfitting to begin with is a good thing! It means our model is learning!!!

## Checking the TensorBoard logs
Now our model has been trained, we can make its performance visual by checking the TensorBoard logs.

The TensorBoard magic function (%tensorboard) will access the logs directory we created earlier and vizualize its contents.
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir drive/My\ Drive/Dog\ Vision/logs

# All the issues that i encountered 

# https://github.com/tensorflow/tensorboard/issues/3186

# https://github.com/tensorflow/tensorboard/issues/1306

# https://stackoverflow.com/questions/59563025/how-to-reset-tensorboard-when-it-tries-to-reuse-a-killed-windows-pid
# https://github.com/tensorflow/tensorboard/issues/3469

# !kill pid

"""Thanks to our `early_stopping` callback, the model stopped training after 13 or so epochs (could be slightly different in each case). This is because the validation accuracy failed to improve for 3 epochs.

But the good new is, we can definitely see our model is learning something. The validation accuracy got to 65% in only a few minutes.

This means, if we were to scale up the number of images, hopefully we'd see the accuracy increase.

## Making and evaluating predictions using a trained model

Before we scale up and train on more data, let's see some other ways we can evaluate our model. Because although accuracy is a pretty good indicator of how our model is doing, it would be even better if we could could see it in action.

Making predictions with a trained model is as calling predict() on it and passing it data in the same format the model was trained on.
"""

val_data

# Make predictions on the validation data (not used to train on)
predictions = model.predict(val_data, verbose=1) # verbose shows us how long there is to go
predictions

# Check the shape of predictions
predictions.shape

len(y_val)

len(unique_breeds)

predictions[0] # we have got 200 arrrays of 120 diffrent numbers that are really small
# Probability value for every single label
# the highest value in this array is going to correspond to the the index of the label that model thinks is most likely

len(predictions[0])

np.sum(predictions[0]) # sums up to 1

"""### Summary for above
Making predictions with our model returns an array with a different value for each label.

In this case, making predictions on the validation data (200 images) returns an array (predictions) of arrays, each containing 120 different values (one for each unique dog breed).

These different values are the probabilities or the likelihood the model has predicted a certain image being a certain breed of dog. The higher the value, the more likely the model thinks a given image is a specific breed of dog.

Now we'd convert an array of probabilities into an actual label.

"""

# First prediction
index = 0
print(predictions[index])
print(f"Max value (probability of prediction): {np.max(predictions[index])}") # the max probability value predicted by the model
print(f"Sum: {np.sum(predictions[index])}") # because we used softmax activation in our model, this will be close to 1
print(f"Max index: {np.argmax(predictions[index])}") # the index of where the max value in predictions[0] occurs
print(f"Predicted label: {unique_breeds[np.argmax(predictions[index])]}") # the predicted label

"""Having this information is great but it would be even better if we could compare a prediction to its true label and original image.

To help us with this, we're building a little function to convert prediction probabilities into predicted labels.

**Note:** Prediction probabilities are also known as confidence levels.

"""

# Turn prediction probabilities into their respective label (easier to understand than above) 
def get_pred_label(prediction_probabilities):
  """
  Turns an array of prediction probabilities into a label.
  """
  return unique_breeds[np.argmax(prediction_probabilities)]

# Get a predicted label based on an array of prediction probabilities
pred_label = get_pred_label(predictions[0])
pred_label

"""

Now since our validation data is still in a batch dataset, we will have to unbatchify it to make predictions on the validation images and then compare those predictions to the validation label."""

val_data

"""Remember, the model hasn't trained on the validation data, during the `fit()` function, it only used the validation data to evaluate itself. So we can use the validation images to visually compare our models predictions with the validation labels.

Since our validation data (`val_data`) is in batch form, to get a list of validation images and labels, we'll have to unbatch it (using [`unbatch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#unbatch)) and then turn it into an iterator using [`as_numpy_iterator()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#as_numpy_iterator).

<------- an alternative  ------->
https://www.udemy.com/course/complete-machine-learning-and-data-science-zero-to-mastery/learn/lecture/17958626#questions/17128702 
"""

# Create a function to unbatch a batch datasetd dataset

def unbatchify(data):
  """
  Takes a batched dataset of (image, label) Tensors and returns separate arrays
  of images and labels.
  """
  images = []
  labels = []
  # Loop through unbatched data
  for image, label in data.unbatch().as_numpy_iterator():
    # print(image) .... image will be in form of a preprocessed image
    # print(label)
    images.append(image)
    labels.append(unique_breeds[np.argmax(label)])
  return images, labels

# Unbatchify the validation data
val_images, val_labels = unbatchify(val_data)
val_images[0], val_labels[0]

get_pred_label(val_labels[0])

# Test for above cell  (should give same output as above)
# images[0], labels[0]
# (labels[0])
# get_pred_label(predictions[0])

"""Now we've got ways to get:
* Prediction labels
* Validation labels (truth labels)
* Validation images

Let's make some functions to make these all a bit more visualize.

More specifically, we want to be able to view an image, its predicted label and its actual label (true label).

The first function we'll create will:
* Take an array of prediction probabilities, an array of truth labels, an array of images and an integer.
* Convert the prediction probabilities to a predicted label.
* Plot the predicted label, its predicted probability, the truth label and target image on a single plot.
"""

def plot_pred(prediction_probabilities, labels, images, n=1):
  """
  View the prediction, ground truth label and image for sample n.
  """
  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]
  
  # Get the pred label
  pred_label = get_pred_label(pred_prob)
  
  # Plot image & remove ticks
  plt.imshow(image)
  plt.xticks([])
  plt.yticks([])

  # Change the color of the title depending on if the prediction is right or wrong
  if pred_label == true_label:
    color = "green"
  else:
    color = "red"

  plt.title("{} {:2.0f}% ({})".format(pred_label,
                                      np.max(pred_prob)*100,
                                      true_label),
                                      color=color)

# View an example prediction, original image and truth label
plot_pred(prediction_probabilities=predictions,
          labels=val_labels,
          images=val_images,
          # n=69
          )

"""Since we're working with a multi-class problem (120 different dog breeds), it would also be good to see what other guesses our model is making. More specifically, if our model predicts a certain label with 24% probability, what else did it predict?

Let's build a function to demonstrate. The function will:
* Take an input of a prediction probabilities array, a ground truth labels array and an integer.
* Find the predicted label using `get_pred_label()`.
* Find the top 10:
  * Prediction probabilities indexes
  * Prediction probabilities values
  * Prediction labels
* Plot the top 10 prediction probability values and labels, coloring the true label green.
"""

def plot_pred_conf(prediction_probabilities, labels, n=1):
  """
  Plots the top 10 highest prediction confidences along with
  the truth label for sample n.
  """
  pred_prob, true_label = prediction_probabilities[n], labels[n]

  # Get the predicted label
  pred_label = get_pred_label(pred_prob)

  # Find the top 10 prediction confidence indexes
  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]
  # Find the top 10 prediction confidence values
  top_10_pred_values = pred_prob[top_10_pred_indexes]
  # Find the top 10 prediction labels
  top_10_pred_labels = unique_breeds[top_10_pred_indexes]

  # Setup plot
  top_plot = plt.bar(np.arange(len(top_10_pred_labels)), 
                     top_10_pred_values, 
                     color="grey")
  
  plt.xticks(np.arange(len(top_10_pred_labels)),
             labels=top_10_pred_labels,
             rotation="vertical")

  # Change color of true label
  if np.isin(true_label, top_10_pred_labels):
    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color("green")
  else:
    pass

plot_pred_conf(prediction_probabilities=predictions,
               labels=val_labels,
               n=9)

"""Wonderful! Now we've got some functions to help us visualize our predictions and evaluate our model, let's check out a few."""

# Let's check a few predictions and their different values
i_multiplier = 0 # modifies our n 
num_rows = 3
num_cols = 2
num_images = num_rows*num_cols

plt.figure(figsize=(5*2*num_cols, 5*num_rows))

for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_pred(prediction_probabilities=predictions,
            labels=val_labels,
            images=val_images,
            n=i+i_multiplier)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_pred_conf(prediction_probabilities=predictions,
                labels=val_labels,
                n=i+i_multiplier)

plt.tight_layout(h_pad=1.0)
plt.show()

"""Create a confusion matrix with our model predictions and true labels
https://medium.datadriveninvestor.com/building-a-confusion-matrix-from-scratch-85a8bfb97626

## Saving and reloading a model

After training a model, it's a good idea to save it. Saving it means you can share it with others, put it in an application and more importantly, won't have to go through the potentially expensive step of retraining it.

The format of an [entire saved Keras model is h5](https://www.tensorflow.org/tutorials/keras/save_and_load). So we'll make a function which can take a model as input and utilise the [`save()`](https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format) method to save it as a h5 file to a specified directory.
"""

def save_model(model, suffix=None):
  """
  Saves a given model in a models directory and appends a suffix (string)
  for clarity and reuse.
  """
  # Create model directory with current time
  modeldir = os.path.join("drive/My Drive/Dog Vision/models",
                          datetime.datetime.now().strftime("%Y%m%d-%H%M%s"))
  model_path = modeldir + "-" + suffix + ".h5" # save format of model
  print(f"Saving model to: {model_path}...")
  model.save(model_path)
  return model_path

"""If we've got a saved model, we'd like to load it, we will create a function which can take a model path and use the [`tf.keras.models.load_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model) function to load it into the notebook.

Because we're using a component from TensorFlow Hub (`hub.KerasLayer`) we'll have to pass this as a parameter to the `custom_objects` parameter.
"""

def load_model(model_path):
  """
  Loads a saved model from a specified path.
  """
  print(f"Loading saved model from: {model_path}")
  model = tf.keras.models.load_model(model_path,
                                     custom_objects={"KerasLayer":hub.KerasLayer})
  return model

# Save our model trained on 1000 images
# save_model(model, suffix="1000-images-mobilenetv2-Adam") # Adam Optimizer

# Load our model trained on 1000 images
model_1000_images = load_model('drive/My Drive/Dog Vision/models/20230405-21091680728948-1000-images-mobilenetv2-Adam.h5')

# if warnings come up then they can be ignored

# Evaluate the pre-saved model
model.evaluate(val_data)

# Evaluate the loaded model
model_1000_images.evaluate(val_data)

"""## Training the model (on the full data)

Now we know our model works on a subset of the data, we can start to move forward with training one on the full data.

Above, we saved all of the training filepaths to `X` and all of the training labels to `y`. Let's check them out.
"""

# Remind ourselves of the size of the full dataset
len(X), len(y)

"""There we go! We've got over 10,000 images and labels in our training set.

Before we can train a model on these, we'll have to turn them into a data batch.

The beautiful thing is, we can use our `create_data_batches()` function from above which also preprocesses our images for us (thank you past us for writing a helpful function).
"""

# Turn full training data in a data batch
full_data = create_data_batches(X, y)

"""Our data is in a data batch, all we need now is a model.

And surprise, we've got a function for that too! Let's use `create_model()` to instantiate another model. 
"""

# Instantiate a new model for training on the full dataset
full_model = create_model()

"""Since we've made a new model instance, `full_model`, we'll need some callbacks too."""

# Create full model callbacks

# TensorBoard callback
full_model_tensorboard = create_tensorboard_callback()

# Early stopping callback
# Note: No validation set when training on all the data, therefore can't monitor validation accruacy
full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor="accuracy",
                                                             patience=3)

"""**Note:** Since running the cell below will cause the model to train on all of the data (10,000+) images, it may take a fairly long time to get started and finish. However, thanks to our `full_model_early_stopping` callback, it'll stop before it starts going too long.

Remember, the first epoch is always the longest as data gets loaded into memory. After it's there, it'll speed up.

While training faced this 

2 root error(s) found.
  (0) NOT_FOUND:  drive/My Drive/Dog Vision/train/4ea20d09a89fb02ac592bdddea31393f.jpg; No such file or directory
	 [[{{node ReadFile}}]]
	 [[IteratorGetNext]]
	 [[IteratorGetNext/_2]]
  (1) NOT_FOUND:  drive/My Drive/Dog Vision/train/4ea20d09a89fb02ac592bdddea31393f.jpg; No such file or directory
	 [[{{node ReadFile}}]]
	 [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_62757]

add the file specified to train folder since there maybe a an error while extracting

"
"""

# Fit the full model to the full training data
# full_model.fit( x = full_data,
#               epochs=NUM_EPOCHS, # i.e. 100
#               callbacks=[full_model_tensorboard, full_model_early_stopping])

"""To monitor the model whilst it trains, we'll load TensorBoard (it should update every 30-seconds or so whilst the model trains).

### Saving and reloading the full model

Even on a GPU, our full model took a while to train. So it's a good idea to save it.

We can do so using our `save_model()` function.

**Challenge:** It may be a good idea to incorporate the `save_model()` function into a `train_model()` function. Or look into setting up a [checkpoint callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint).
"""

# Save model to file
# save_model(full_model, suffix="full-image-set-mobilenetv2-Adam")

# Load in the full model
loaded_full_model = load_model('drive/My Drive/Dog Vision/models/20230406-15391680795567-full-image-set-mobilenetv2-Adam.h5')

"""### Making predictions on the test dataset

Since our model has been trained on images in the form of Tensor batches, to make predictions on the test data, we'll have to get it into the same format.

We created `create_data_batches()` earlier which can take a list of filenames as input and convert them into Tensor batches.

To make predictions on the test data, we'll:
* Get the test image filenames.
* Convert the filenames into test data batches using `create_data_batches()` and setting the `test_data` parameter to `True` (since there are no labels with the test images).
* Make a predictions array by passing the test data batches to the `predict()` function.
"""

# Load test image filenames (since we're using os.listdir(), these already have .jpg)
test_path = "drive/My Drive/Dog Vision/Extracted/extract/test/"
test_filenames = [test_path + fname for fname in os.listdir(test_path)]

test_filenames[:10]

len(test_filenames)

# Create test data batch

test_data = create_data_batches(test_filenames, test_data=True)

test_data

"""**Note:** Since there are 10,000+ test images, making predictions could take a while, even on a GPU. So beware running the cell below may take up to an hour."""

# Make predictions on test data batch using the loaded full model
# test_predictions = loaded_full_model.predict(test_data,
#                                             verbose=1)

# no. of batches = 10,367/32 = 324

# Save predictions (NumPy array) to csv file (for access later)

# np.savetxt("drive/My Drive/Dog Vision/preds_array.csv", test_predictions, delimiter =",",)

# Load predictions (NumPy array) from csv file
test_predictions = np.loadtxt("drive/My Drive/Dog Vision/preds_array.csv", delimiter = ",")

test_predictions[:10]

test_predictions.shape

"""### Preparing test dataset predictions for Kaggle

Looking at the [Kaggle sample submission](https://www.kaggle.com/c/dog-breed-identification/overview/evaluation), it looks like they want the models output probabilities each for label along with the image ID's.

To get the data in this format, we'll:
*   Create a pandas DataFrame with an ID column as well as a column for each dog breed.
*   Add data to the ID column by extracting the test image ID's from their filepaths.
* Add data (the prediction probabilities) to each of the dog breed columns using the `unique_breeds` list and the `test_predictions` list.
* Export the DataFrame as a CSV to submit it to Kaggle.

"""

# ["id"] + list(unique_breeds)

# Create pandas DataFrame with empty columns
preds_df = pd.DataFrame(columns=["id"] + list(unique_breeds))
preds_df.head()

# Append test image ID's to predictions DataFrame
# test_ids = [os.path.splitext(path) for path in os.listdir(test_path)]
# test_ids

test_path = "drive/My Drive/Dog Vision/Extracted/extract/test/"
preds_df["id"] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]
preds_df.head()

# Add the prediction probabilities to each dog breed column
preds_df[list(unique_breeds)] = test_predictions
preds_df.head()

"""###Exporting our predictions DataFrame to CSV so we can submit it to Kaggle.

"""

preds_df.to_csv("drive/My Drive/Dog Vision/full_model_predictions_submission_1_mobilenetV2.csv",
                index = False
               )

"""## Making predictions on custom images

It's great being able to make predictions on a test dataset already provided for us.

But how could we use our model on our own images?

The premise remains, if we want to make predictions on our own custom images, we have to pass them to the model in the same format the model was trained on.

To do so, we'll:
* Get the filepaths of our own images.
* Turn the filepaths into data batches using `create_data_batches()`. And since our custom images won't have labels, we set the `test_data` parameter to `True`.
* Pass the custom image data batch to our model's `predict()` method.
* Convert the prediction output probabilities to prediction labels.
* Compare the predicted labels to the custom images.

**Note:** To make predictions on custom images, I've uploaded pictures of my own to a directory located at `drive/My Drive/Dog Vision/my-dogs/` (as seen in the cell below). In order to make predictions on your own images, you will have to do something similar.
"""

# Our custom filepaths

custom_path = "drive/My Drive/Dog Vision/my-dogs/"
custom_image_paths = [ custom_path + fname for fname in os.listdir(custom_path) ]

custom_image_paths

# Turn custom images into batch datasets

custom_data = create_data_batches(custom_image_paths, test_data=True)
custom_data

# Make predictions on the custom data
custom_preds = loaded_full_model.predict(custom_data)
custom_preds

custom_preds.shape

# Get custom  image prediction labels

custom_pred_labels = [get_pred_label(custom_preds[i]) for i in range(len(custom_preds))]
custom_pred_labels

# Get custom images (our unbatchify() function won't work since there aren't labels)
custom_images = []
# Loop through unbatched data
for image in custom_data.unbatch().as_numpy_iterator():
  custom_images.append(image)

# Check custom image predictions
plt.figure(figsize=(10, 10))
for i, image in enumerate(custom_images):
  plt.subplot(1,len(custom_pred_labels) , i+1) # plt.subplot(1, len(custom_pred_labels), i+1)
  plt.xticks([])
  plt.yticks([])
  plt.title(custom_pred_labels[i])
  plt.imshow(image)

